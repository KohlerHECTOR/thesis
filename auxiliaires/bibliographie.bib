@article{cancer,
  title={Reinforcement learning for precision oncology},
  author={Eckardt, Jan-Niklas and Wendt, Karsten and Bornhaeuser, Martin and Middeke, Jan Moritz},
  journal={Cancers},
  volume={13},
  number={18},
  pages={4624},
  year={2021},
  publisher={MDPI}
}

@TechReport{   unrapport,
  author = {Nom, Prénom},
  title = {Titre du rapport technique},
  institution = {Institution où le rapport a vu le jour},
  date = {2012}
}

@Manual{   amsmath,
  title = {User's Guide for the \textsf{amsmath} Package},
  organization = {American Mathematical Society},
  date = {2002-02-25}
}



@article{black-box2,
author = {Shao, Yijun and Cheng, Yan and Shah, Rashmee U. and Weir, Charlene R. and Bray, Bruce E. and Zeng-Treitler, Qing},
title = {Shedding Light on the Black Box: Explaining Deep Neural Network Prediction of Clinical Outcomes},
year = {2021},
issue_date = {Jan 2021},
publisher = {Plenum Press},
address = {USA},
volume = {45},
number = {1},
issn = {0148-5598},
url = {https://doi.org/10.1007/s10916-020-01701-8},
doi = {10.1007/s10916-020-01701-8},
abstract = {Deep neural network models are emerging as an important method in healthcare delivery, following the recent success in other domains such as image recognition. Due to the multiple non-linear inner transformations, deep neural networks are viewed by many as black boxes. For practical use, deep learning models require explanations that are intuitive to clinicians. In this study, we developed a deep neural network model to predict outcomes following major cardiovascular procedures, using temporal image representation of past medical history as input. We created a novel explanation for the prediction of the model by defining impact scores that associate clinical observations with the outcome. For comparison, a logistic regression model was fitted to the same dataset. We compared the impact scores and log odds ratios by calculating three types of correlations, which provided a partial validation of the impact scores. The deep neural network model achieved an area under the receiver operating characteristics curve (AUC) of 0.787, compared to 0.746 for the logistic regression model. Moderate correlations were found between the impact scores and the log odds ratios. Impact scores generated by the explanation algorithm has the potential to shed light on the “black box” deep neural network model and could facilitate its adoption by clinicians.},
journal = {J. Med. Syst.},
month = jan,
numpages = {9},
keywords = {Machine learning, Clinical outcome, Predictive model, Deep neural network}
}


@PhDThesis{   agriculture,
  author = {Gautron, Romain},
  title = {FApprentissage par renforcement pour l'aide à la conduite des cultures des petits agriculteurs des pays du Sud: vers la maîtrise des risques.},
  school = {Montpellier SupAgro},
  date = {2022}
}

@PhDThesis{   driving,
  author = {Leurent, Edouard},
  title = {Safe and Efficient Reinforcement Learning for Behavioural Planning in Autonomous Driving},
  school = {Universit\'e de Lille},
  date = {2020}
}

@PhDThesis{   knuth63,
  author = {Knuth, Donald Ervin},
  title = {Finite semifields and projective planes},
  school = {California Institute of Technology},
  date = {1963}
}

@Book{boole,
author={Boole, George},
title={The Laws of Thought},
year={1854},
publisher={Walton and Maberly Macmillan and Co.}}

@Book{sl,
author={Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar},
title={Foundations of Machine Learning},
year={2012},
publisher={MIT Press}}

@Article{ turing,
author = {Turing, Alan},
title = {Computing Machinery and Intelligence},
journal = {Mind},
year = {1950}}
%%%%%%%%%%%%% RL %%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{mctavish2022fast,
  title={Fast sparse decision tree optimization via reference ensembles},
  author={McTavish, Hayden and Zhong, Chudi and Achermann, Reto and Karimalis, Ilias and Chen, Jacques and Rudin, Cynthia and Seltzer, Margo},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={36},
  number={9},
  pages={9604--9613},
  year={2022}
}

@inproceedings{lookahead,
author = {Murthy, Sreerama and Salzberg, Steven},
title = {Lookahead and pathology in decision tree induction},
year = {1995},
isbn = {1558603638},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {The standard approach to decision tree induction is a top-down greedy agorithm that makes locally optimal irrevocable decisions at each node of a tree. In this paper we empircally study an alternative approach in which the algorithms use one-level lookahead to decide what test to use at a node. we systematically compare using a very large number of artificial data sets the quality of dimension trees induced by the greedy approach to that of trees induced using lookahead. The main observations from our experiments are (1) the greedy approach consistently produced trees that were just as at accurate as trees produced with the much more expensive lookahead step and (n) we observed many instances of pathology, i.e, lookahead produced trees that were both larger and less accurate than trees produced without it.},
booktitle = {Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2},
pages = {1025–1031},
numpages = {7},
location = {Montreal, Quebec, Canada},
series = {IJCAI'95}
}

@Book{Bellman,
author = {Bellman, Richard},
title = {Dynamic Programming},
year = {1957}
}

@Article{atari,
author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
title = {The arcade learning environment: an evaluation platform for general agents},
year = {2013},
issue_date = {May 2013},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {47},
number = {1},
issn = {1076-9757},
abstract = {In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available.},
journal = {J. Artif. Int. Res.},
month = may,
pages = {253–279},
numpages = {27}
}


@InProceedings{hmmdp,
  title = 	 {Solving Hidden-Mode Markov Decision Problems},
  author =       {Choi, Samuel Ping-Man and Zhang, Nevin Lianwen and Yeung, Dit-Yan},
  booktitle = 	 {Proceedings of the Eighth International Workshop on Artificial Intelligence and Statistics},
  pages = 	 {49--56},
  year = 	 {2001},
  editor = 	 {Richardson, Thomas S. and Jaakkola, Tommi S.},
  volume = 	 {R3},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {04--07 Jan},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/r3/choi01a/choi01a.pdf},
  url = 	 {https://proceedings.mlr.press/r3/choi01a.html},
  abstract = 	 {Markov decision processes (HM-MDPs) are a novel mathematical framework for a subclass of nonstationary reinforcement learning problems where environment dynamics change over time according to a Markov process. HM-MDPs are a special case of partially observable Markov decision processes (POMDPs), and therefore nonstationary problems of this type can in principle be addressed indirectly via existing POMDP algorithms. However, previous research has shown that such an indirect approach is inefficient compared with a direct HM-MDP approach in terms of the model learning time. In this paper, we investigate how to solve HM-MDP problems efficiently by using a direct approach. We exploit the HM-MDP structure and derive an equation for dynamic programming update. Our equation decomposes the value function into a number of components and as a result, substantially reduces the amount of computations in finding optimal policies. Based on the incremental pruning and point-based improvement techniques, a value iteration algorithm is also implemented. Empirical results show that the HM-MDP approach outperforms the POMDP one several order of magnitude with respect to both space requirement and speed.},
  note =         {Reissued by PMLR on 31 March 2021.}
}


@inproceedings{littman1,
author = {Littman, Michael L.},
title = {Memoryless policies: theoretical limitations and practical results},
year = {1994},
isbn = {0262531224},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Proceedings of the Third International Conference on Simulation of Adaptive Behavior : From Animals to Animats 3: From Animals to Animats 3},
pages = {238–245},
numpages = {8},
location = {Brighton, United Kingdom},
series = {SAB94}
}

@inproceedings{sarsa-pomdp,
author = {Loch, John and Singh, Satinder P.},
title = {Using Eligibility Traces to Find the Best Memoryless Policy in Partially Observable Markov Decision Processes},
year = {1998},
isbn = {1558605568},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Fifteenth International Conference on Machine Learning},
pages = {323–331},
numpages = {9},
series = {ICML '98}
}

@inproceedings{justif-asym,
title={A Theoretical Justification for Asymmetric Actor-Critic algorithms},
author={Gaspard Lambrechts and Damien Ernst and Aditya Mahajan},
booktitle={Forty-second International Conference on Machine Learning},
year={2025},
url={https://openreview.net/forum?id=F1yANMCnAn}
}

@inproceedings{jsj,
author = {Jaakkola, Tommi and Singh, Satinder P. and Jordan, Michael I.},
title = {Reinforcement learning algorithm for partially observable Markov decision problems},
year = {1994},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {Increasing attention has been paid to reinforcement learning algorithms in recent years, partly due to successes in the theoretical analysis of their behavior in Markov environments. If the Markov assumption is removed, however, neither generally the algorithms nor the analyses continue to be usable. We propose and analyze a new learning algorithm to solve a certain class of non-Markov decision problems. Our algorithm applies to problems in which the environment is Markov, but the learner has restricted access to state information. The algorithm involves a Monte-Carlo policy evaluation combined with a policy improvement method that is similar to that of Markov decision problems and is guaranteed to converge to a local maximum. The algorithm operates in the space of stochastic policies, a space which can yield a policy that performs considerably better than any deterministic policy. Although the space of stochastic policies is continuous--even for a discrete action space--our algorithm is computationally tractable.},
booktitle = {Proceedings of the 8th International Conference on Neural Information Processing Systems},
pages = {345–352},
numpages = {8},
location = {Denver, Colorado},
series = {NIPS'94}
}

@article{lambrechts2025informed,
    title={Informed {POMDP}: {L}everaging Additional Information in Model-Based {RL}},
    author={Lambrechts, Gaspard and Bolland, Adrien and Ernst, Damien},
    journal={Reinforcement Learning Journal},
    volume={2},
    pages={763--784},
    year={2025}
}

@inproceedings{learning-pomdp,
author = {Singh, Satinder P. and Jaakkola, Tommi S. and Jordan, Michael I.},
title = {Learning without state-estimation in partially observable Markovian decision processes},
year = {1994},
isbn = {1558603352},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Eleventh International Conference on International Conference on Machine Learning},
pages = {284–292},
numpages = {9},
location = {New Brunswick, NJ, USA},
series = {ICML'94}
}

@inproceedings{momdp,
  TITLE = {{A Closer Look at MOMDPs}},
  AUTHOR = {Araya-L{\'o}pez, Mauricio and Thomas, Vincent and Buffet, Olivier and Charpillet, Fran{\c c}ois},
  URL = {https://inria.hal.science/inria-00535559},
  BOOKTITLE = {{Proceedings of the 22nd International Conference on Tools with Artificial Intelligence}},
  ADDRESS = {Arras, France},
  PUBLISHER = {{IEEE}},
  SERIES = {Proceedings of the 22nd International Conference on Tools with Artificial Intelligence},
  YEAR = {2010},
  MONTH = Oct,
  KEYWORDS = {Partially Observable Markov Decision Processes ; Mixed Observability Markov Decision Processes ; POMDP ; MOMDP},
  PDF = {https://inria.hal.science/inria-00535559v1/file/ictai10.pdf},
  HAL_ID = {inria-00535559},
  HAL_VERSION = {v1},
}

@Article{gymnasium,
  title={Gymnasium: A Standard Interface for Reinforcement Learning Environments},
  author={Towers, Mark and Kwiatkowski, Ariel and Terry, Jordan and Balis, John U and De Cola, Gianluca and Deleu, Tristan and Goul{\~a}o, Manuel and Kallinteris, Andreas and Krimmel, Markus and KG, Arjun and others},
  journal={arXiv preprint arXiv:2407.17032},
  year={2024}
}

@Article{fi-rl3,
title={Distilling Reinforcement Learning Policies for Interpretable Robot Locomotion: Gradient Boosting Machines and Symbolic Regression},
author={Fernando Acero and Zhibin Li},
booktitle={Workshop on Interpretable Policies in Reinforcement Learning @RLC-2024},
year={2024},
url={https://openreview.net/forum?id=fa3fjH3dEW}
}
@Article{fi-rl2,
title={An Attentive Approach for Building Partial Reasoning Agents from Pixels},
author={Safa Alver and Doina Precup},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
url={https://openreview.net/forum?id=S3FUKFMRw8},
note={}
}
@Article{fi-rl,
title={Piecewise Linear Parametrization of Policies: Towards Interpretable Deep Reinforcement Learning},
author={Maxime Wabartha and Joelle Pineau},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=hOMVq57Ce0}
}
@Article{sympol,
title={Mitigating Information Loss in Tree-Based Reinforcement Learning via Direct Optimization},
author={Sascha Marton and Tim Grams and Florian Vogt and Stefan L{\"u}dtke and Christian Bartelt and Heiner Stuckenschmidt},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=qpXctF2aLZ}
}


@InProceedings{silva,
  title = 	 {Optimization Methods for Interpretable Differentiable Decision Trees Applied to Reinforcement Learning},
  author =       {Silva, Andrew and Gombolay, Matthew and Killian, Taylor and Jimenez, Ivan and Son, Sung-Hyun},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1855--1865},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/silva20a/silva20a.pdf},
  url = 	 {https://proceedings.mlr.press/v108/silva20a.html},
  abstract = 	 { Decision trees are ubiquitous in machine learning for their ease of use and interpretability. Yet, these models are not typically employed in reinforcement learning as they cannot be updated online via stochastic gradient descent. We overcome this limitation by allowing for a gradient update over the entire tree that improves sample complexity affords interpretable policy extraction. First, we include theoretical motivation on the need for policy-gradient learning by examining the properties of gradient descent over differentiable decision trees. Second, we demonstrate that our approach equals or outperforms a neural network on all domains and can learn discrete decision trees online with average rewards up to 7x higher than a batch-trained decision tree. Third, we conduct a user study to quantify the interpretability of a decision tree, rule list, and a neural network with statistically significant results (p &lt; 0.001).}
}


@Article{insight,
    title={End-to-End Neuro-Symbolic Reinforcement Learning with Textual Explanations},
    author={Luo, Lirui and Zhang, Guoxi and Xu, Hongming and Yang, Yaodong and Fang, Cong and Li, Qing},
    journal={International Conference on Machine Learning (ICML)},
    year={2024}
}

@Article{hierarchical,
title={Hierarchical Reinforcement Learning by Discovering Intrinsic Options},
author={Jesse Zhang and Haonan Yu and Wei Xu},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=r-gPPHEjpmw}
}


@misc{sparsity,
      title={Induced Modularity and Community Detection for Functionally Interpretable Reinforcement Learning}, 
      author={Anna Soligo and Pietro Ferraro and David Boyle},
      year={2025},
      eprint={2501.17077},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.17077}, 
}

@Article{pirl2,
title={Programmatic Reinforcement Learning without Oracles},
author={Wenjie Qiu and He Zhu},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=6Tk2noBdvxt}
}

@Article{leap,
title={Learning to Synthesize Programs as Interpretable and Generalizable Policies},
author={Dweep Trivedi and Jesse Zhang and Shao-Hua Sun and Joseph J Lim},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=wP9twkexC3V}
}

@Article{scobots,
title={Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents},
author={Quentin Delfosse and Sebastian Sztwiertnia and Mark Rothermel and Wolfgang Stammer and Kristian Kersting},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=ZC0PSk6Mc6}
}

@Article{lin2025hierarchical,
  title={Hierarchical Programmatic Option Framework},
  author={Lin, Yu-An and Lee, Chen-Tao and Yang, Chih-Han and Liu, Guan-Ting and Sun, Shao-Hua},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@Article{shindo2024blendrl,
  title={BlendRL: A Framework for Merging Symbolic and Neural Policy Learning},
  author={Shindo, Hikaru and Delfosse, Quentin and Dhami, Devendra Singh and Kersting, Kristian},
  journal={arXiv},
  year={2025}
}

@Article{zahra,
      title={Assessing the Interpretability of Programmatic Policies with Large Language Models}, 
      author={Zahra Bashir and Michael Bowling and Levi H. S. Lelis},
      year={2024},
      eprint={2311.06979},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@Article{milani-survey,
author = {Milani, Stephanie and Topin, Nicholay and Veloso, Manuela and Fang, Fei},
title = {Explainable Reinforcement Learning: A Survey and Comparative Review},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3616864},
doi = {10.1145/3616864},
abstract = {Explainable reinforcement learning (XRL) is an emerging subfield of explainable machine learning that has attracted considerable attention in recent years. The goal of XRL is to elucidate the decision-making process of reinforcement learning (RL) agents in sequential decision-making settings. Equipped with this information, practitioners can better understand important questions about RL agents (especially those deployed in the real world), such as what the agents will do and why. Despite increased interest, there exists a gap in the literature for organizing the plethora of papers—especially in a way that centers the sequential decision-making nature of the problem. In this survey, we propose a novel taxonomy for organizing the XRL literature that prioritizes the RL setting. We propose three high-level categories: feature importance, learning process and Markov decision process, and policy-level. We overview techniques according to this taxonomy, highlighting challenges and opportunities for future work. We conclude by using these gaps to motivate and outline a roadmap for future work.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {168},
numpages = {36},
keywords = {Explainable reinforcement learning, interpretability, explainability}
}

@Article{glanois-survey,
  title={A survey on interpretable reinforcement learning},
  author={Glanois, Claire and Weng, Paul and Zimmer, Matthieu and Li, Dong and Yang, Tianpei and Hao, Jianye and Liu, Wulong},
  journal={Machine Learning},
  pages={1--44},
  year={2024},
  publisher={Springer}
}

@Article{dagger,
  title={A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning},
  author={St{\'e}phane Ross and Geoffrey J. Gordon and J. Andrew Bagnell},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2010},
}

@Article{viper,
  title={Verifiable Reinforcement Learning via Policy Extraction},
  author={Osbert Bastani and Yewen Pu and Armando Solar-Lezama},
  booktitle={Neural Information Processing Systems},
  year={2018},
}
@Article{behavior-cloning,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  journal={Advances in neural information processing systems},
  volume={1},
  year={1988}
}

@Article{dqn,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@Article{ppo,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@InProceedings{deep-rl-relu1,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author =       {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf},
  url = 	 {https://proceedings.mlr.press/v80/haarnoja18b.html},
  abstract = 	 {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.}
}

@Article{deep-rl-relu2,
title={Randomized Ensembled Double Q-Learning: Learning Fast Without a Model},
author={Xinyue Chen and Che Wang and Zijian Zhou and Keith W. Ross},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=AY8zfZm0tDd}
}

@article{barez-chain-2025,
  title = {Chain-of-Thought Is Not Explainability},
  author = {Barez, Fazl and Wu, Tung-Yu and Arcuschin, Iván and Lan, Michael and Wang, Vincent and Siegel, Noah and Collignon, Nicolas and Neo, Clement and Lee, Isabelle and Paren, Alasdair and Bibi, Adel and Trager, Robert and Fornasiere, Damiano and Yan, John and Elazar, Yanai and Bengio, Yoshua},
  year = {2025},
  conference = {Under Review},
  topic = {Interpretability}
}
@Article{deep-rl-relu3,
title={Dropout Q-Functions for Doubly Efficient Reinforcement Learning},
author={Takuya Hiraoka and Takahisa Imagawa and Taisei Hashimoto and Takashi Onishi and Yoshimasa Tsuruoka},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=xCVJMsPv3RT}
}

@Article{pids,
    title={An Open-Loop Baseline for Reinforcement Learning Locomotion Tasks},
    author={Raffin, Antonin and Sigaud, Olivier and Kober, Jens and Albu-Schaeffer, Alin and Silv{\'{e}}rio, Jo{\~{a}}o and Stulp, Freek},
    journal={Reinforcement Learning Journal},
    volume={1},
    pages={92--107},
    year={2024}
}

@Article{PIRL,
  title={Programmatically interpretable reinforcement learning},
  author={Verma, Abhinav and Murali, Vijayaraghavan and Singh, Rishabh and Kohli, Pushmeet and Chaudhuri, Swarat},
  booktitle={International conference on machine learning},
  pages={5045--5054},
  year={2018},
  organization={PMLR}
}

@Article{rliable,
  title={Deep Reinforcement Learning at the Edge of the Statistical Precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel
          and Courville, Aaron and Bellemare, Marc G},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{td-gammon,
author = {Tesauro, Gerald},
title = {Temporal difference learning and TD-Gammon},
year = {1995},
issue_date = {March 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/203330.203343},
doi = {10.1145/203330.203343},
abstract = {Ever since the days of Shannon's proposal for a chess-playing algorithm [12] and Samuel's checkers-learning program [10] the domain of complex board games such as Go, chess, checkers, Othello, and backgammon has been widely regarded as an ideal testing ground for exploring a variety of concepts and approaches in artificial intelligence and machine learning. Such board games offer the challenge of tremendous complexity and sophistication required to play at expert level. At the same time, the problem inputs and performance measures are clear-cut and well defined, and the game environment is readily automated in that it is easy to simulate the board, the rules of legal play, and the rules regarding when the game is over and determining the outcome.},
journal = {Commun. ACM},
month = mar,
pages = {58–68},
numpages = {11}
}

@article{dyna,
author = {Sutton, Richard S.},
title = {Dyna, an integrated architecture for learning, planning, and reacting},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {0163-5719},
url = {https://doi.org/10.1145/122344.122377},
doi = {10.1145/122344.122377},
abstract = {Dyna is an AI architecture that integrates learning, planning, and reactive execution. Learning methods are used in Dyna both for compiling planning results and for updating a model of the effects of the agent's actions on the world. Planning is incremental and can use the probabilistic and ofttimes incorrect world models generated by learning processes. Execution is fully reactive in the sense that no planning intervenes between perception and action. Dyna relies on machine learning methods for learning from examples---these are among the basic building blocks making up the architecture---yet is not tied to any particular method. This paper briefly introduces Dyna and discusses its strengths and weaknesses with respect to other architectures.},
journal = {SIGART Bull.},
month = jul,
pages = {160–163},
numpages = {4}
}

@inproceedings{random-search,
author = {Mania, Horia and Guy, Aurelia and Recht, Benjamin},
title = {Simple random search of static linear policies is competitive for reinforcement learning},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Model-free reinforcement learning aims to offer off-the-shelf solutions for controlling dynamical systems without requiring models of the system dynamics. We introduce a model-free random search algorithm for training static, linear policies for continuous control problems. Common evaluation methodology shows that our method matches state-of-the-art sample efficiency on the benchmark MuJoCo locomotion tasks. Nonetheless, more rigorous evaluation reveals that the assessment of performance on these benchmarks is optimistic. We evaluate the performance of our method over hundreds of random seeds and many different hyperparameter configurations for each benchmark task. This extensive evaluation is possible because of the small computational footprint of our method. Our simulations highlight a high variability in performance in these benchmark tasks, indicating that commonly used estimations of sample efficiency do not adequately evaluate the performance of RL algorithms. Our results stress the need for new baselines, benchmarks and evaluation methodology for RL algorithms.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {1805–1814},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{pg_sutton,
 author = {Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Solla and T. Leen and K. M\"{u}ller},
 pages = {},
 publisher = {MIT Press},
 title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
 url = {https://proceedings.neurips.cc/paper_files/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf},
 volume = {12},
 year = {1999}
}

@book{sutton,
    title={Reinforcement Learning: {A}n Introduction},
    author={Sutton, Richard S. and Barto, Andrew G.},
	publisher={The MIT Press},
	year={1998},
	address={Cambridge, MA},
}

@Article{viper,
 author = {Bastani, Osbert and Pu, Yewen and Solar-Lezama, Armando},
 journal = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Verifiable Reinforcement Learning via Policy Extraction},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/e6d8545daa42d5ced125a4bf747b3688-Paper.pdf},
 volume = {31},
 year = {2018}
}

@article{POMDP,
 ISSN = {0030364X, 15265463},
 URL = {http://www.jstor.org/stable/169635},
 abstract = {This paper treats the discounted cost, optimal control problem for Markov processes with incomplete state information. The optimization approach for these partially observable Markov processes is a generalization of the well-known policy iteration technique for finding optimal stationary policies for completely observable Markov processes. The state space for the problem is the space of state occupancy probability distributions (the unit simplex). The development of the algorithm introduces several new ideas, including the class of finitely transient policies, which are shown to possess piecewise linear cost functions. The paper develops easily implemented approximations to stationary policies based on these finitely transient policies and shows that the concave hull of an approximation can be included in the well-known Howard policy improvement algorithm with subsequent convergence. The paper closes with a detailed example illustrating the application of the algorithm to the two-state partially observable Markov process.},
 author = {Edward J. Sondik},
 journal = {Operations Research},
 number = {2},
 pages = {282--304},
 publisher = {INFORMS},
 title = {The Optimal Control of Partially Observable Markov Processes Over the Infinite Horizon: Discounted Costs},
 urldate = {2025-08-14},
 volume = {26},
 year = {1978}
}

@Article{topin2021iterative,
  title={Iterative bounding mdps: Learning interpretable policies via non-interpretable methods},
  author={Topin, Nicholay and Milani, Stephanie and Fang, Fei and Veloso, Manuela},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={9923--9931},
  year={2021}
}


@Manual{zoo,
  author = {Raffin, Antonin},
  title = {RL Baselines3 Zoo},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
}

@Article{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {International Conference on Intelligent Robots andSystems (IROS)},
  pages = {5026-5033},
  publisher = {IEEE},
  title = {MuJoCo: A physics engine for model-based control.},
  year = 2012
}

@Article{nudge,
  title={Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction},
  author={Quentin Delfosse and Hikaru Shindo and Devendra Singh Dhami and Kristian Kersting},
  journal    = {Advances in Neural Information Processing (NeurIPS)},
  year={2023},
}


@inbook{chap2,
author = {Dutech, Alain and Scherrer, Bruno},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781118557426},
title = {Partially Observable Markov Decision Processes},
booktitle = {Markov Decision Processes in Artificial Intelligence},
chapter = {7},
pages = {185-228},
doi = {https://doi.org/10.1002/9781118557426.ch7},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118557426.ch7},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118557426.ch7},
year = {2013},
keywords = {belief states, information state, Markov decision processes (MDPs), partially observable Markov decision processes (POMDPs), policy iteration, value function, value iteration},
abstract = {Summary This chapter deals with Partially Observable Markov Decision Processes (POMDPs). It details the POMDP framework and introduces the notion of information state. There exist some generic concepts that help design exact algorithms, based on Value Iteration or Policy Iteration. Like for Markov decision processes (MDPs), solving a POMDP aims at maximizing a given performance criterion. Except for a small sub-family of POMDPs called “transient”, the sequence of belief states generated by a given policy is made of an infinite number of different belief states. Similarly to MDPs, a value function exists for POMDPs defined on information states. The chapter studies in more details the properties of policies defined on observations so as to better understand the differences between POMDPs and MDPs. Controlled Vocabulary Terms iterative methods}
}

@article{madumal, title={Explainable Reinforcement Learning through a Causal Lens}, volume={34}, url={https://ojs.aaai.org/index.php/AAAI/article/view/5631}, DOI={10.1609/aaai.v34i03.5631}, abstractNote={&lt;p&gt;Prominent theories in cognitive science propose that humans understand and represent the knowledge of the world through causal relationships. In making sense of the world, we build &lt;em&gt;causal models&lt;/em&gt; in our mind to encode cause-effect relations of events and use these to &lt;em&gt;explain&lt;/em&gt; why new events happen by referring to counterfactuals — things that did not happen. In this paper, we use causal models to derive causal explanations of the behaviour of model-free reinforcement learning agents. We present an approach that learns a &lt;em&gt;structural causal model&lt;/em&gt; during reinforcement learning and encodes causal relationships between variables of interest. This model is then used to generate explanations of behaviour based on counterfactual analysis of the causal model. We computationally evaluate the model in 6 domains and measure performance and task prediction accuracy. We report on a study with 120 participants who observe agents playing a real-time strategy game (Starcraft II) and then receive explanations of the agents’ behaviour. We investigate: 1) participants’ understanding gained by explanations through task prediction; 2) explanation satisfaction and 3) trust. Our results show that causal model explanations perform better on these measures compared to two other baseline explanation models.&lt;/p&gt;}, number={03}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Madumal, Prashan and Miller, Tim and Sonenberg, Liz and Vetere, Frank}, year={2020}, month={Apr.}, pages={2493-2500} }}

@inproceedings{Atrey2020Exploratory,
title={Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning},
author={Akanksha Atrey and Kaleigh Clary and David Jensen},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkl3m1BFDB}
}


@ARTICLE{attention,
  author={Shi, Wenjie and Huang, Gao and Song, Shiji and Wang, Zhuoyuan and Lin, Tingyu and Wu, Cheng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Self-Supervised Discovering of Interpretable Features for Reinforcement Learning}, 
  year={2022},
  volume={44},
  number={5},
  pages={2712-2724},
  keywords={Task analysis;Decision making;Perturbation methods;Reinforcement learning;Jacobian matrices;Visualization;Games;Deep reinforcement learning;interpretability;attention map;decision-making process},
  doi={10.1109/TPAMI.2020.3037898}}


@inproceedings{shap,
author = {Lundberg, Scott M. and Lee, Su-In},
title = {A unified approach to interpreting model predictions},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {4768–4777},
numpages = {10},
location = {Long Beach, California, USA},
series = {NIPS'17}
}


@inproceedings{Puri2020Explain,
title={Explain Your Move: Understanding Agent Actions Using Specific and Relevant Feature Attribution},
author={Nikaash Puri and Sukriti Verma and Piyush Gupta and Dhruv Kayastha and Shripad Deshmukh and Balaji Krishnamurthy and Sameer Singh},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SJgzLkBKPB}
}

@Article{ocatari,
    title={{OCAtari}: {O}bject-Centric {Atari} 2600 Reinforcement Learning Environments},
    author={Delfosse, Quentin and Bl{\"{u}}ml, Jannis and Gregori, Bjarne and Sztwiertnia, Sebastian and Kersting, Kristian},
    journal={Reinforcement Learning Journal},
    volume={1},
    pages={400--449},
    year={2024}
}

@Article{mdpdt,
author = {Vos, Dani\"{e}l and Verwer, Sicco},
title = {Optimal decision tree policies for Markov decision processes},
year = {2023},
isbn = {978-1-956792-03-4},
url = {https://doi.org/10.24963/ijcai.2023/606},
doi = {10.24963/ijcai.2023/606},
abstract = {Interpretability of reinforcement learning policies is essential for many real-world tasks but learning such interpretable policies is a hard problem. Particularly, rule-based policies such as decision trees and rules lists are difficult to optimize due to their non-differentiability. While existing techniques can learn verifiable decision tree policies, there is no guarantee that the learners generate a policy that performs optimally. In this work, we study the optimization of size-limited decision trees for Markov Decision Processes (MPDs) and propose OMDTs: Optimal MDP Decision Trees. Given a user-defined size limit and MDP formulation, OMDT directly maximizes the expected discounted return for the decision tree using Mixed-Integer Linear Programming. By training optimal tree policies for different MDPs we empirically study the optimality gap for existing imitation learning techniques and find that they perform suboptimally. We show that this is due to an inherent shortcoming of imitation learning, namely that complex policies cannot be represented using size-limited trees. In such cases, it is better to directly optimize the tree for expected return. While there is generally a trade-off between the performance and interpretability of machine learning models, we find that on small MDPs, depth 3 OMDTs often perform close to optimally.},
journal = {Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence},
articleno = {606},
numpages = {9},
location = {Macao, P.R.China},
series = {IJCAI '23}
}
@Article{Dulac_Arnold_2011,
   title={Datum-Wise Classification: A Sequential Approach to Sparsity},
   ISBN={9783642237805},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-642-23780-5_34},
   DOI={10.1007/978-3-642-23780-5_34},
   journal={Machine Learning and Knowledge Discovery in Databases},
   publisher={Springer Berlin Heidelberg},
   author={Dulac-Arnold, Gabriel and Denoyer, Ludovic and Preux, Philippe and Gallinari, Patrick},
   year={2011},
   pages={375–390} }

@Article{garlapati2015reinforcementlearningapproachonline,
      title={A Reinforcement Learning Approach to Online Learning of Decision Trees}, 
      author={Abhinav Garlapati and Aditi Raghunathan and Vaishnavh Nagarajan and Balaraman Ravindran},
      year={2015},
      eprint={1507.06923},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1507.06923}, 
}


@Article{vos2024optimizinginterpretabledecisiontree,
      title={Optimizing Interpretable Decision Tree Policies for Reinforcement Learning}, 
      author={Daniël Vos and Sicco Verwer},
      year={2024},
      eprint={2408.11632},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.11632}, 
}


@Article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
}
@Manual{rlberry,
    author = {Domingues, Omar Darwiche and Flet-Berliac, Yannis and Leurent, Edouard and M{\'e}nard, Pierre and Shang, Xuedong and Valko, Michal},
    doi = {10.5281/zenodo.5544540},
    month = {10},
    title = {{rlberry - A Reinforcement Learning Library for Research and Education}},
    url = {https://github.com/rlberry-py/rlberry},
    year = {2021}
}

@Book{puterman,
  title   = {Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  year    = {1994},
  publisher = {John Wiley \& Sons},
  author = {Martin L. Puterman}
}

%%%%%%%%%%%%% Decision Trees %%%%%%%%%%%%%%%

@Article{random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@Article{npcomplete,
title = {Constructing optimal binary decision trees is NP-complete},
journal = {Information Processing Letters},
volume = {5},
number = {1},
pages = {15-17},
year = {1976},
issn = {0020-0190},
doi = {https://doi.org/10.1016/0020-0190(76)90095-8},
url = {https://www.sciencedirect.com/science/article/pii/0020019076900958},
author = {Laurent Hyafil and Ronald L. Rivest},
keywords = {Binary decision trees, computational complexity, NP-complete}
}

@Article{MDL,
title = {Modeling by shortest data description},
journal = {Automatica},
volume = {14},
number = {5},
pages = {465-471},
year = {1978},
issn = {0005-1098},
doi = {https://doi.org/10.1016/0005-1098(78)90005-5},
url = {https://www.sciencedirect.com/science/article/pii/0005109878900055},
author = {J. Rissanen},
keywords = {Modeling, parameter estimation, identification, statistics, stochastic systems},
}

@misc{study-5,
      title={An Evaluation of the Human-Interpretability of Explanation}, 
      author={Isaac Lage and Emily Chen and Jeffrey He and Menaka Narayanan and Been Kim and Sam Gershman and Finale Doshi-Velez},
      year={2019},
      eprint={1902.00006},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1902.00006}, 
}

@article{study-7,
author = {Huysmans, Johan and Dejaeger, Karel and Mues, Christophe and Vanthienen, Jan and Baesens, Bart},
title = {An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models},
year = {2011},
issue_date = {April, 2011},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {51},
number = {1},
issn = {0167-9236},
url = {https://doi.org/10.1016/j.dss.2010.12.003},
doi = {10.1016/j.dss.2010.12.003},
abstract = {An important objective of data mining is the development of predictive models. Based on a number of observations, a model is constructed that allows the analysts to provide classifications or predictions for new observations. Currently, most research focuses on improving the accuracy or precision of these models and comparatively little research has been undertaken to increase their comprehensibility to the analyst or end-user. This is mainly due to the subjective nature of 'comprehensibility', which depends on many factors outside the model, such as the user's experience and his/her prior knowledge. Despite this influence of the observer, some representation formats are generally considered to be more easily interpretable than others. In this paper, an empirical study is presented which investigates the suitability of a number of alternative representation formats for classification when interpretability is a key requirement. The formats under consideration are decision tables, (binary) decision trees, propositional rules, and oblique rules. An end-user experiment was designed to test the accuracy, response time, and answer confidence for a set of problem-solving tasks involving the former representations. Analysis of the results reveals that decision tables perform significantly better on all three criteria, while post-test voting also reveals a clear preference of users for decision tables in terms of ease of use.},
journal = {Decis. Support Syst.},
month = apr,
pages = {141–154},
numpages = {14},
keywords = {Classification, Comprehensibility, Data mining, Decision tables, Knowledge representation}
}

@misc{study-6,
      title={Assessing the Local Interpretability of Machine Learning Models}, 
      author={Dylan Slack and Sorelle A. Friedler and Carlos Scheidegger and Chitradeep Dutta Roy},
      year={2019},
      eprint={1902.03501},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1902.03501}, 
}


@Article{murthy1994system,
  title={A system for induction of oblique decision trees},
  author={Murthy, Sreerama K and Kasif, Simon and Salzberg, Steven},
  journal={Journal of artificial intelligence research},
  volume={2},
  pages={1--32},
  year={1994}
}

@Article{somepalli2021saintimprovedneuralnetworks,
      title={SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training}, 
      author={Gowthami Somepalli and Micah Goldblum and Avi Schwarzschild and C. Bayan Bruss and Tom Goldstein},
      year={2021},
      eprint={2106.01342},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.01342}, 
}

@Article{NEURIPS2018_185c29dc,
 author = {Carreira-Perpinan, Miguel A. and Tavallali, Pooya},
 journal = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Alternating optimization of decision trees, with application to learning sparse oblique trees},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/185c29dc24325934ee377cfda20e414c-Paper.pdf},
 volume = {31},
 year = {2018}
}
@Article{9534446,
  author={Zharmagambetov, Arman and Gabidolla, Magzhan and Carreira-Perpiñán, Miguel Ê.},
  journal={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Improved Boosted Regression Forests Through Non-Greedy Tree Optimization}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  keywords={Computer vision;Runtime;Signal processing algorithms;Forestry;Signal processing;Boosting;Inference algorithms},
  doi={10.1109/IJCNN52387.2021.9534446}}

@Article{10.1145/3412815.3416882,
author = {Carreira-Perpi\~{n}\'{a}n, Miguel \'{A} and Zharmagambetov, Arman},
title = {Ensembles of Bagged TAO Trees Consistently Improve over Random Forests, AdaBoost and Gradient Boosting},
year = {2020},
isbn = {9781450381031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412815.3416882},
doi = {10.1145/3412815.3416882},
abstract = {Ensemble methods based on trees, such as Random Forests, AdaBoost and gradient boosting, are widely recognized as among the best off-the-shelf classifiers: they typically achieve state-of-the-art accuracy in many problems with little effort in tuning hyperparameters, and they are often used in applications, possibly combined with other methods such as neural nets. While many variations of forest methods exist, using different diversity mechanisms (such as bagging, feature sampling or boosting), nearly all rely on training individual trees in a highly suboptimal way using greedy top-down tree induction algorithms such as CART or C5.0. We study forests where each tree is trained on a bootstrapped or random sample but using the recently proposed tree alternating optimization (TAO), which is able to learn trees that have both fewer nodes and lower error. The better optimization of individual trees translates into forests that achieve higher accuracy but using fewer, smaller trees with oblique nodes. We demonstrate this in a range of datasets and with a careful study of the complementary effect of optimization and diversity in the construction of the forest. These bagged TAO trees improve consistently and by a considerable margin over Random Forests, AdaBoost, gradient boosting and other forest algorithms in every single dataset we tried.},
journal = {Proceedings of the 2020 ACM-IMS on Foundations of Data Science Conference},
pages = {35–46},
numpages = {12},
keywords = {random forests, ensemble learning, decision tree optimization, bagging},
location = {Virtual Event, USA},
series = {FODS '20}
}

@Article{10.1145/3637528.3671903,
author = {Kairgeldin, Rasul and Carreira-Perpi\~{n}\'{a}n, Miguel \'{A}.},
title = {Bivariate Decision Trees: Smaller, Interpretable, More Accurate},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671903},
doi = {10.1145/3637528.3671903},
abstract = {Univariate decision trees, commonly used since the 1950s, predict by asking questions about a single feature in each decision node. While they are interpretable, they often lack competitive predictive accuracy due to their inability to model feature correlations. Multivariate (oblique) trees use multiple features in each node, capturing high-dimensional correlations better, but sometimes they can be difficult to interpret. We advocate for a model that strikes a useful middle ground: bivariate decision trees, which use two features in each node. This typically produces trees that not only are more accurate than univariate trees, but much smaller, which offsets the small increase in node complexity and keeps them interpretable. They also help data mining by constructing new features that are useful for discrimination, and by providing a form of supervised, hierarchical 2D visualization that reveals patterns such as clusters or linear structure. We give two new algorithms to learn bivariate trees: a fast one based on CART; and a slower one based on alternating optimization with a feature regularization term, which produces the best trees while still scaling to large datasets.},
journal = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1336–1347},
numpages = {12},
keywords = {decision trees, interpretability, pairwise interactions},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{fmdp,
author = {Boutilier, Craig and Dearden, Richard and Goldszmidt, Moises},
title = {Exploiting structure in policy construction},
year = {1995},
isbn = {1558603638},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {Markov decision processes (MDPs) have recently been applied to the problem of modeling decision-theoretic planning. While traditional methods for solving MDPs are often practical for small states spaces, their effectiveness for large AI planning problems is questionable. We present an algorithm, called structured policy Iteration (SPI), that constructs optimal policies without explicit enumeration of the state space. The algorithm retains the fundamental computational steps of the commonly used modified policy iteration algorithm, but exploits the variable and prepositional independencies reflected in a temporal Bayesian network representation of MDPs. The principles behind SPI can be applied to any structured representation of stochastic actions, policies and value functions, and the algorithm itself can be used in conjunction with recent approximation methods.},
booktitle = {Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2},
pages = {1104–1111},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {IJCAI'95}
}

@Article{loh2014fifty,
  title={Fifty years of classification and regression trees},
  author={Loh, Wei-Yin},
  journal={International Statistical Review},
  volume={82},
  number={3},
  pages={329--348},
  year={2014},
  publisher={Wiley Online Library}
}

@Article{bad-greedy,
author = {Murthy, Sreerama and Salzberg, Steven},
title = {Decision tree induction: how effective is the greedy heuristic?},
year = {1995},
publisher = {AAAI Press},
abstract = {Most existing decision tree systems use a greedy approach to induce trees — locally optimal splits are induced at every node of the tree. Although the greedy approach is suboptimal, it is believed to produce reasonably good trees. In the current work, we attempt to verify this belief. We quantify the goodness of greedy tree induction empirically, using the popular decision tree algorithms, C4.5 and CART. We induce decision trees on thousands of synthetic data sets and compare them to the corresponding optimal trees, which in turn are found using a novel map coloring idea. We measure the effect on greedy induction of variables such as the underlying concept complexity, training set size, noise and dimensionality. Our experiments show, among other things, that the expected classification cost of a greedily induced tree is consistently very close to that of the optimal tree.},
journal = {Proceedings of the First International Conference on Knowledge Discovery and Data Mining},
pages = {222–227},
numpages = {6},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {KDD'95}
}


@Article{Murthy,
author = {Murthy, Sreerama and Salzberg, Steven},
title = {Lookahead and Pathology in Decision Tree Induction},
year = {1995},
isbn = {1558603638},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {The standard approach to decision tree induction is a top-down greedy agorithm that makes locally optimal irrevocable decisions at each node of a tree. In this paper we empircally study an alternative approach in which the algorithms use one-level lookahead to decide what test to use at a node. we systematically compare using a very large number of artificial data sets the quality of dimension trees induced by the greedy approach to that of trees induced using lookahead. The main observations from our experiments are (1) the greedy approach consistently produced trees that were just as at accurate as trees produced with the much more expensive lookahead step and (n) we observed many instances of pathology, i.e, lookahead produced trees that were both larger and less accurate than trees produced without it.},
journal = {Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2},
pages = {1025–1031},
numpages = {7},
location = {Montreal, Quebec, Canada},
series = {IJCAI'95}
}

@Article{oct,
  title={Optimal classification trees},
  author={Bertsimas, Dimitris and Dunn, Jack},
  journal={Machine Learning},
  volume={106},
  pages={1039--1082},
  year={2017},
  publisher={Springer}
}
@Article{verwer2017learning,
  title={Learning decision trees with flexible constraints and objectives using integer optimization},
  author={Verwer, Sicco and Zhang, Yingqian},
  journal={Integration of AI and OR Techniques in Constraint Programming: 14th International Conference, CPAIOR 2017, Padua, Italy, June 5-8, 2017, Proceedings 14},
  pages={94--103},
  year={2017},
  organization={Springer}
}
@Article{binoct,
  title={Learning optimal classification trees using a binary linear program formulation},
  author={Verwer, Sicco and Zhang, Yingqian},
  journal={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  pages={1625--1632},
  year={2019}
}

@Article{mfoct,
      title={Learning Optimal Classification Trees: Strong Max-Flow Formulations}, 
      author={Sina Aghaei and Andres Gomez and Phebe Vayanos},
      year={2020},
      eprint={2002.09142},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@Article{lin2020generalized,
  title={Generalized and scalable optimal sparse decision trees},
  author={Lin, Jimmy and Zhong, Chudi and Hu, Diane and Rudin, Cynthia and Seltzer, Margo},
  journal={International Conference on Machine Learning},
  pages={6150--6160},
  year={2020},
  organization={PMLR}
}

@Article{quantbnb,
  title = 	 {Quant-{B}n{B}: A Scalable Branch-and-Bound Method for Optimal Decision Trees with Continuous Features},
  author =       {Mazumder, Rahul and Meng, Xiang and Wang, Haoyue},
  journal = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {15255--15277},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/mazumder22a/mazumder22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/mazumder22a.html},
  abstract = 	 {Decision trees are one of the most useful and popular methods in the machine learning toolbox. In this paper, we consider the problem of learning optimal decision trees, a combinatorial optimization problem that is challenging to solve at scale. A common approach in the literature is to use greedy heuristics, which may not be optimal. Recently there has been significant interest in learning optimal decision trees using various approaches (e.g., based on integer programming, dynamic programming)—to achieve computational scalability, most of these approaches focus on classification tasks with binary features. In this paper, we present a new discrete optimization method based on branch-and-bound (BnB) to obtain optimal decision trees. Different from existing customized approaches, we consider both regression and classification tasks with continuous features. The basic idea underlying our approach is to split the search space based on the quantiles of the feature distribution—leading to upper and lower bounds for the underlying optimization problem along the BnB iterations. Our proposed algorithm Quant-BnB shows significant speedups compared to existing approaches for shallow optimal trees on various real datasets.}
}


@inproceedings{baisero-ppo,
author = {Baisero, Andrea and Amato, Christopher},
title = {Unbiased Asymmetric Reinforcement Learning under Partial Observability},
year = {2022},
isbn = {9781450392136},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {In partially observable reinforcement learning, offline training gives access to latent information which is not available during online training and/or execution, such as the system state. Asymmetric actor-critic methods exploit such information by training a history-based policy via a state-based critic. However, many asymmetric methods lack theoretical foundation, and are only evaluated on limited domains. We examine the theory of asymmetric actor-critic methods which use state-based critics, and expose fundamental issues which undermine the validity of a common variant, and limit its ability to address partial observability. We propose an unbiased asymmetric actor-critic variant which is able to exploit state information while remaining theoretically sound, maintaining the validity of the policy gradient theorem, and introducing no bias and relatively low variance into the training process. An empirical evaluation performed on domains which exhibit significant partial observability confirms our analysis, demonstrating that unbiased asymmetric actor-critic converges to better policies and/or faster than symmetric and biased asymmetric baselines.},
booktitle = {Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems},
pages = {44–52},
numpages = {9},
keywords = {actor-critic, partial observability, reinforcement learning},
location = {Virtual Event, New Zealand},
series = {AAMAS '22}
}

@InProceedings{baisero-dqn,
  title = 	 {Asymmetric {DQN} for partially observable reinforcement learning},
  author =       {Baisero, Andrea and Daley, Brett and Amato, Christopher},
  booktitle = 	 {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},
  pages = 	 {107--117},
  year = 	 {2022},
  editor = 	 {Cussens, James and Zhang, Kun},
  volume = 	 {180},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {01--05 Aug},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v180/baisero22a/baisero22a.pdf},
  url = 	 {https://proceedings.mlr.press/v180/baisero22a.html},
  abstract = 	 {Offline training in simulated partially observable environments allows reinforcement learning methods to exploit privileged state information through a mechanism known as asymmetry. Such privileged information has the potential to greatly improve the optimal convergence properties, if used appropriately. However, current research in asymmetric reinforcement learning is often heuristic in nature, with few connections to underlying theory or theoretical guarantees, and is primarily tested through empirical evaluation. In this work, we develop the theory of Asymmetric Policy Iteration, an exact model-based dynamic programming solution method, and then apply relaxations which eventually result in Asymmetric DQN, a model-free deep reinforcement learning algorithm. Our theoretical findings are complemented and validated by empirical experimentation performed in environments which exhibit significant amounts of partial observability, and require both information gathering strategies and memorization.}
}


@Article{murtree,
  author  = {Emir Demirovic and Anna Lukina and Emmanuel Hebrard and Jeffrey Chan and James Bailey and Christopher Leckie and Kotagiri Ramamohanarao and Peter J. Stuckey},
  title   = {MurTree: Optimal Decision Trees via Dynamic Programming and Search},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {26},
  pages   = {1--47},
  url     = {http://jmlr.org/papers/v23/20-520.html}
}


@Article{blossom,
  title = 	 {Blossom: an Anytime algorithm for Computing Optimal Decision Trees},
  author =       {Demirovi\'{c}, Emir and Hebrard, Emmanuel and Jean, Louis},
  journal = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {7533--7562},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/demirovic23a/demirovic23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/demirovic23a.html},
  abstract = 	 {We propose a simple algorithm to learn optimal decision trees of bounded depth. This algorithm is essentially an anytime version of the state-of-the-art dynamic programming approach. It has virtually no overhead compared to heuristic methods and is comparable to the best exact methods to prove optimality on most data sets. Experiments show that whereas existing exact methods hardly scale to deep trees, this algorithm learns trees comparable to standard heuristics without computational overhead, and can significantly improve their accuracy when given more computation time, even for deep trees.}
}

@Article{pystreed,
 author = {van der Linden, Jacobus and de Weerdt, Mathijs and Demirovi\'{c}, Emir},
 journal = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Neumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {9173--9212},
 publisher = {Curran Associates, Inc.},
 title = {Necessary and Sufficient Conditions for Optimal Decision Trees using Dynamic Programming},
 volume = {36},
 year = {2023}
}


@Article{chaouki2024branchesfastdynamicprogramming,
      title={Branches: A Fast Dynamic Programming and Branch {\&} Bound algorithm for Optimal Decision Trees}, 
      author={Ayman Chaouki and Jesse Read and Albert Bifet},
      year={2024},
      eprint={2406.02175},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.02175}, 
}

@Article{vanderlinden2024optimalgreedydecisiontrees,
      title={Optimal or Greedy Decision Trees? Revisiting their Objectives, Tuning, and Performance}, 
      author={Jacobus G. M. van der Linden and Daniël Vos and Mathijs M. de Weerdt and Sicco Verwer and Emir Demirović},
      year={2024},
      eprint={2409.12788},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.12788}, 
}

@Article{MLSYS2021_0184b0cd,
 author = {Bouthillier, Xavier and Delaunay, Pierre and Bronzi, Mirko and Trofimov, Assya and Nichyporuk, Brennan and Szeto, Justin and Mohammadi Sepahvand, Nazanin and Raff, Edward and Madan, Kanika and Voleti, Vikram and Ebrahimi Kahou, Samira and Michalski, Vincent and Arbel, Tal and Pal, Chris and Varoquaux, Gael and Vincent, Pascal},
 journal = {Proceedings of Machine Learning and Systems},
 editor = {A. Smola and A. Dimakis and I. Stoica},
 pages = {747--769},
 title = {Accounting for Variance in Machine Learning Benchmarks},
 url = {https://proceedings.mlsys.org/paper_files/paper/2021/file/0184b0cd3cfb185989f858a1d9f5c1eb-Paper.pdf},
 volume = {3},
 year = {2021}
}

@Article{10.1145/2641190.2641198,
author = {Vanschoren, Joaquin and van Rijn, Jan N. and Bischl, Bernd and Torgo, Luis},
title = {OpenML: networked science in machine learning},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/2641190.2641198},
doi = {10.1145/2641190.2641198},
abstract = {Many sciences have made significant breakthroughs by adopting online tools that help organize, structure and mine information that is too detailed to be printed in journals. In this paper, we introduce OpenML, a place for machine learning researchers to share and organize data in fine detail, so that they can work more effectively, be more visible, and collaborate with others to tackle harder problems. We discuss how OpenML relates to other examples of networked science and what benefits it brings for machine learning research, individual scientists, as well as students and practitioners.},
journal = {SIGKDD Explor. Newsl.},
month = jun,
pages = {49–60},
numpages = {12}
}

@Article{higgs_280,
  author       = {Whiteson, Daniel},
  title        = {{HIGGS}},
  year         = {2014},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5V312}
}

@Article{covertype_31,
  author       = {Blackard, Jock},
  title        = {{Covertype}},
  year         = {1998},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C50K5N}
}

@Article{wistuba2015learning,
  title={Learning hyperparameter optimization initializations},
  author={Wistuba, Martin and Schilling, Nicolas and Schmidt-Thieme, Lars},
  journal={2015 IEEE international conference on data science and advanced analytics (DSAA)},
  pages={1--10},
  year={2015},
  organization={IEEE}
}

@Article{ komer-proc-scipy-2014,
  author    = { {B}rent {K}omer and {J}ames {B}ergstra and {C}hris {E}liasmith },
  title     = { {H}yperopt-{S}klearn: {A}utomatic {H}yperparameter {C}onfiguration for {S}cikit-{L}earn },
  journal = { {P}roceedings of the 13th {P}ython in {S}cience {C}onference },
  pages     = { 32 - 37 },
  year      = { 2014 },
  editor    = { {S}t\'efan van der {W}alt and {J}ames {B}ergstra },
  doi       = { 10.25080/Majora-14bd3278-006 }
}
@Article{JMLR:v23:21-0992,
  author  = {Matthias Feurer and Katharina Eggensperger and Stefan Falkner and Marius Lindauer and Frank Hutter},
  title   = {Auto-Sklearn 2.0: Hands-free AutoML via Meta-Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {261},
  pages   = {1--61},
  url     = {http://jmlr.org/papers/v23/21-0992.html}
}

@Article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@Article{sklearn_api,
  author    = {Lars Buitinck and Gilles Louppe and Mathieu Blondel and
                Fabian Pedregosa and Andreas Mueller and Olivier Grisel and
                Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort
                and Jaques Grobler and Robert Layton and Jake VanderPlas and
                Arnaud Joly and Brian Holt and Ga{\"{e}}l Varoquaux},
  title     = {{API} design for machine learning software: experiences from the scikit-learn
                project},
  journal = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
  year      = {2013},
  pages = {108--122},
}



@Article{ke2017lightgbm,
  title={Lightgbm: A highly efficient gradient boosting decision tree},
  author={Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
  journal={Advances in neural information processing systems},
  volume={30},
  pages={3146--3154},
  year={2017}
}

BibTeX
@article{black-box,
author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
title = {A Survey of Methods for Explaining Black Box Models},
year = {2018},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3236009},
doi = {10.1145/3236009},
abstract = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {93},
numpages = {42},
keywords = {Open the black box, explanations, interpretability, transparent models}
}

@inproceedings{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
  pages={4171--4186},
  year={2019}
}

@article{tokamak,
  title={Magnetic control of tokamak plasmas through deep reinforcement learning},
  author={Degrave, Jonas and Felici, Federico and Buchli, Jonas and Neunert, Michael and Tracey, Brendan and Carpanese, Francesco and Ewalds, Timo and Hafner, Roland and Abdolmaleki, Abbas and de Las Casas, Diego and others},
  journal={Nature},
  volume={602},
  number={7897},
  pages={414--419},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{lenet,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

@article{perceptron,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}

@Article{pmlr-v28-bergstra13,
  title = 	 {Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures},
  author = 	 {Bergstra, James and Yamins, Daniel and Cox, David},
  journal = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {115--123},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {1},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/bergstra13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/bergstra13.html},
  abstract = 	 {Many computer vision algorithms depend on configuration settings that are typically hand-tuned in the course of evaluating the algorithm for a particular data set. While such parameter tuning is often presented as being incidental to the algorithm, correctly setting these parameter choices is frequently critical to realizing a method’s full potential. Compounding matters, these parameters often must be re-tuned when the algorithm is applied to a new problem domain, and the tuning process itself often depends on personal experience and intuition in ways that are hard to quantify or describe. Since the performance of a given technique depends on both the fundamental quality of the algorithm and the details of its tuning, it is sometimes difficult to know whether a given technique is genuinely better, or simply better tuned.     In this work, we propose a meta-modeling approach to support automated hyperparameter optimization, with the goal of providing practical tools that replace hand-tuning with a reproducible and unbiased optimization process. Our approach is to expose the underlying expression graph of how a performance metric (e.g. classification accuracy on validation examples) is computed from hyperparameters that govern not only how individual processing steps are applied, but even which processing steps are included.  A hyperparameter optimization algorithm transforms this graph into a program for optimizing that performance metric.  Our approach yields state of the art results on three disparate computer vision problems: a face-matching verification task (LFW), a face identification task (PubFig83) and an object recognition task (CIFAR-10), using a single broad class of feed-forward vision architectures.  }
}


@Article{pruning1,
  title={A comparative analysis of methods for pruning decision trees},
  author={Esposito, Floriana and Malerba, Donato and Semeraro, Giovanni and Kay, J},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={19},
  number={5},
  pages={476--491},
  year={1997},
  publisher={IEEE}
}
@Article{Hollmann2025,
  author = {Hollmann, Noah and Müller, Samuel and Purucker, Lennart and Krishnakumar, Arjun and Körfer, Max and Hoo, Shi Bin and Schirrmeister, Robin Tibor and Hutter, Frank},
  year = {2025},
  title = {Accurate predictions on small data with a tabular foundation model},
  journal = {Nature},
  volume = {637},
  number = {8045},
  pages = {319--326},
  doi = {10.1038/s41586-024-08328-6},
  issn = {1476-4687},
  abstract = {Tabular data, spreadsheets organized in rows and columns, are ubiquitous across scientific fields, from biomedicine to particle physics to economics and climate science1,2. The fundamental prediction task of filling in missing values of a label column based on the rest of the columns is essential for various applications as diverse as biomedical risk models, drug discovery and materials science. Although deep learning has revolutionized learning from raw data and led to numerous high-profile success stories3–5, gradient-boosted decision trees6–9 have dominated tabular data for the past 20 years. Here we present the Tabular Prior-data Fitted Network (TabPFN), a tabular foundation model that outperforms all previous methods on datasets with up to 10,000 samples by a wide margin, using substantially less training time. In 2.8 s, TabPFN outperforms an ensemble of the strongest baselines tuned for 4 h in a classification setting. As a generative transformer-based foundation model, this model also allows fine-tuning, data generation, density estimation and learning reusable embeddings. TabPFN is a learning algorithm that is itself learned across millions of synthetic datasets, demonstrating the power of this approach for algorithm development. By improving modelling abilities across diverse fields, TabPFN has the potential to accelerate scientific discovery and enhance important decision-making in various domains.}
}
@Article{pruning2,
  title={A comparative study of reduced error pruning method in decision tree algorithms},
  author={Mohamed, W Nor Haizan W and Salleh, Mohd Najib Mohd and Omar, Abdul Halim},
  journal={2012 IEEE International conference on control system, computing and engineering},
  pages={392--397},
  year={2012},
  organization={IEEE}
}
@Article{10.5555/3327757.3327770,
author = {Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
title = {CatBoost: unbiased boosting with categorical features},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results.},
journal = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6639–6649},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}
@Article{9533597,
  author={Zharmagambetov, Arman and Hada, Suryabhan Singh and Gabidolla, Magzhan and Carreira-Perpiñán, Miguel Á.},
  journal={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Non-Greedy algorithms for Decision Tree Optimization: An Experimental Comparison}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  keywords={Training;Neural networks;Forestry;Classification algorithms;Partitioning algorithms;Optimization;Regression tree analysis},
  doi={10.1109/IJCNN52387.2021.9533597}}

@Article{NIPS2015_1579779b,
 author = {Norouzi, Mohammad and Collins, Maxwell and Johnson, Matthew A and Fleet, David J and Kohli, Pushmeet},
 journal = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Efficient Non-greedy Optimization of Decision Trees},
 url = {https://proceedings.neurips.cc/paper_files/paper/2015/file/1579779b98ce9edb98dd85606f2c119d-Paper.pdf},
 volume = {28},
 year = {2015}
}

@Article{schapire1990strength,
  title={The strength of weak learnability},
  author={Schapire, Robert E},
  journal={Machine learning},
  volume={5},
  pages={197--227},
  year={1990},
  publisher={Springer}
}

@Article{FREUND1997119,
title = {A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting},
journal = {Journal of Computer and System Sciences},
volume = {55},
number = {1},
pages = {119-139},
year = {1997},
issn = {0022-0000},
doi = {https://doi.org/10.1006/jcss.1997.1504},
url = {https://www.sciencedirect.com/science/article/pinterii/S002200009791504X},
author = {Yoav Freund and Robert E Schapire},
abstract = {In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone–Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line.}
}

@misc{pinto,
      title={Asymmetric Actor Critic for Image-Based Robot Learning}, 
      author={Lerrel Pinto and Marcin Andrychowicz and Peter Welinder and Wojciech Zaremba and Pieter Abbeel},
      year={2017},
      eprint={1710.06542},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/1710.06542}, 
}

@Book{book-boosting,
author = {Zhou, Zhi-Hua},
title = {Ensemble Methods: Foundations and algorithms},
year = {2012},
isbn = {1439830037},
publisher = {Chapman \& Hall/CRC},
edition = {1st},
abstract = {An up-to-date, self-contained introduction to a state-of-the-art machine learning approach, Ensemble Methods: Foundations and algorithms shows how these accurate methods are used in real-world tasks. It gives you the necessary groundwork to carry out further research in this evolving field. After presenting background and terminology, the book covers the main algorithms and theories, including Boosting, Bagging, Random Forest, averaging and voting schemes, the Stacking method, mixture of experts, and diversity measures. It also discusses multiclass extension, noise tolerance, error-ambiguity and bias-variance decompositions, and recent progress in information theoretic diversity. Moving on to more advanced topics, the author explains how to achieve better performance through ensemble pruning and how to generate better clustering results by combining multiple clusterings. In addition, he describes developments of ensemble methods in semi-supervised learning, active learning, cost-sensitive learning, class-imbalance learning, and comprehensibility enhancement.}
}


@Article{grinsztajn2022tree,
  title={Why do tree-based models still outperform deep learning on typical tabular data?},
  author={Grinsztajn, L{\'e}o and Oyallon, Edouard and Varoquaux, Ga{\"e}l},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={507--520},
  year={2022}
}

@Book{hastie2009elements,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor},
  year={2009},
  publisher={Springer}
}

@Article{cortes1995support,
  title={Support-Vector Networks},
  author={Cortes, Corinna},
  journal={Machine Learning},
  year={1995}
}

@Article{21221,
  author={Goodman, R.M. and Smyth, P.},
  journal={IEEE Transactions on Information Theory}, 
  title={Decision tree design from a communication theory standpoint}, 
  year={1988},
  volume={34},
  number={5},
  pages={979-994},
}


@Article{garey1974performance,
  title={Performance bounds on the splitting algorithm for binary testing},
  author={Garey, Michael R and Graham, Ronald L.},
  journal={Acta Informatica},
  volume={3},
  number={4},
  pages={347--355},
  year={1974},
  publisher={Springer}
}

@Article{GEY20123523,
title = {Risk bounds for CART classifiers under a margin condition},
journal = {Pattern Recognition},
volume = {45},
number = {9},
pages = {3523-3534},
year = {2012},
note = {Best Papers of Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA'2011)},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2012.02.021},
url = {https://www.sciencedirect.com/science/article/pii/S0031320312000994},
author = {Servane Gey},
keywords = {Classification, CART, Pruning, Margin, Risk bounds},
abstract = {Non-asymptotic risk bounds for Classification And Regression Trees (CART) classifiers are obtained in the binary supervised classification framework under a margin assumption on the joint distribution of the covariates and the labels. These risk bounds are derived conditionally on the construction of the maximal binary tree and allow to prove that the linear penalty used in the CART pruning algorithm is valid under the margin condition. It is also shown that, conditionally on the construction of the maximal tree, the final selection by test sample does not alter dramatically the estimation accuracy of the Bayes classifier.}
}

@Book{breiman1984classification,
  title={Classification and Regression Trees},
  author={Breiman, L and Friedman, JH and Olshen, R and Stone, CJ},
  year={1984},
  publisher={Wadsworth}
}

@Book{hutter2005universal,
  title={Universal artificial intelligence: Sequential decisions based on algorithmic probability},
  author={Hutter, Marcus},
  year={2005},
  publisher={Springer Science \& Business Media}
}

@Article{ID3,
author = {Quinlan, J. R.},
title = {Induction of Decision Trees},
year = {1986},
publisher = {Kluwer Academic Publishers},
volume = {1},
number = {1},
journal = {Mach. Learn.},
pages = {81–106},
}

@misc{vos2024optimizinginterpretabledecisiontree,
      title={Optimizing Interpretable Decision Tree Policies for Reinforcement Learning}, 
      author={Daniël Vos and Sicco Verwer},
      year={2024},
      eprint={2408.11632},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.11632}, 
}

@misc{dt-maze,
      title={There is no Accuracy-Interpretability Tradeoff in Reinforcement Learning for Mazes}, 
      author={Yishay Mansour and Michal Moshkovitz and Cynthia Rudin},
      year={2022},
      eprint={2206.04266},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.04266}, 
}

@ARTICLE{cartpole,
  author={Barto, Andrew G. and Sutton, Richard S. and Anderson, Charles W.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics}, 
  title={Neuronlike adaptive elements that can solve difficult learning control problems}, 
  year={1983},
  volume={SMC-13},
  number={5},
  pages={834-846},
  keywords={Adaptive systems;Problem-solving;Training;Pattern recognition;Neurons;Supervised learning;Biological neural networks},
  doi={10.1109/TSMC.1983.6313077}}


@inproceedings{dt-opt-mdp,
author = {Vos, Dani\"{e}l and Verwer, Sicco},
title = {Optimal decision tree policies for Markov decision processes},
year = {2023},
isbn = {978-1-956792-03-4},
url = {https://doi.org/10.24963/ijcai.2023/606},
doi = {10.24963/ijcai.2023/606},
abstract = {Interpretability of reinforcement learning policies is essential for many real-world tasks but learning such interpretable policies is a hard problem. Particularly, rule-based policies such as decision trees and rules lists are difficult to optimize due to their non-differentiability. While existing techniques can learn verifiable decision tree policies, there is no guarantee that the learners generate a policy that performs optimally. In this work, we study the optimization of size-limited decision trees for Markov Decision Processes (MPDs) and propose OMDTs: Optimal MDP Decision Trees. Given a user-defined size limit and MDP formulation, OMDT directly maximizes the expected discounted return for the decision tree using Mixed-Integer Linear Programming. By training optimal tree policies for different MDPs we empirically study the optimality gap for existing imitation learning techniques and find that they perform suboptimally. We show that this is due to an inherent shortcoming of imitation learning, namely that complex policies cannot be represented using size-limited trees. In such cases, it is better to directly optimize the tree for expected return. While there is generally a trade-off between the performance and interpretability of machine learning models, we find that on small MDPs, depth 3 OMDTs often perform close to optimally.},
booktitle = {Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence},
articleno = {606},
numpages = {9},
location = {Macao, P.R.China},
series = {IJCAI '23}
}

@Article{c45,
  title={C4. 5: Programs for machine learning},
  author={Quinlan, J Ross},
  journal={Morgan Kaufmann google schola},
  volume={2},
  pages={203--228},
  year={1993}
}

@Article{how-eff,
author = {Murthy, Sreerama and Salzberg, Steven},
title = {Decision tree induction: how effective is the greedy heuristic?},
year = {1995},
publisher = {AAAI Press},
journal = {Proceedings of the First International Conference on Knowledge Discovery and Data Mining},
pages = {222–227},
}


@Article{zhuang2024learning,
title={Learning a Decision Tree algorithm with Transformers},
author={Yufan Zhuang and Liyuan Liu and Chandan Singh and Jingbo Shang and Jianfeng Gao},
journal={Transactions on Machine Learning Research},
year={2024},
}

@Article{stcohFriedman,
author = {Friedman, Jerome H.},
title = {Stochastic gradient boosting},
year = {2002},
publisher = {Elsevier Science Publishers B. V.},
volume = {38},
number = {4},
journal = {Comput. Stat. Data Anal.},
pages = {367–378},
}

@Article{FriedmanBoosting,
 author = {Jerome H. Friedman},
 journal = {The Annals of Statistics},
 number = {5},
 pages = {1189--1232},
 publisher = {Institute of Mathematical Statistics},
 title = {Greedy Function Approximation: A Gradient Boosting Machine},
 volume = {29},
 year = {2001}
}


@Article{resnet,
author = {Gorishniy, Yury and Rubachev, Ivan and Khrulkov, Valentin and Babenko, Artem},
title = {Revisiting deep learning models for tabular data},
year = {2024},
publisher = {Curran Associates Inc.},
journal = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
}


@Article{xgb,
author = {Chen, Tianqi and Guestrin, Carlos},
title = {XGBoost: A Scalable Tree Boosting System},
year = {2016},
publisher = {Association for Computing Machinery},
journal = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {785–794},
}



@Article{nunes,
author = {Nunes, Cecília and De Craene, Mathieu and Langet, Hélène and Camara, Oscar and Jonsson, Anders},
title = {Learning decision trees through Monte Carlo tree search: An empirical evaluation},
journal = {WIREs Data Mining and Knowledge Discovery},
volume = {10},
number = {3},
year = {2020}
}

@Article{costa2023recent,
  title={Recent advances in decision trees: An updated survey},
  author={Costa, Vin{\'\i}cius G and Pedreira, Carlos E},
  journal={Artificial Intelligence Review},
  volume={56},
  pages={4765--4800},
  year={2023},
  publisher={Springer}
}

@Article{topk,
 author = {Blanc, Guy and Lange, Jane and Pabbaraju, Chirag and Sullivan, Colin and Tan, Li-Yang and Tiwari, Mo},
 journal = {Advances in Neural Information Processing Systems},
 pages = {80220--80232},
 publisher = {Curran Associates, Inc.},
 title = {Harnessing the power of choices in decision tree learning},
 volume = {36},
 year = {2023}
}

@article{festor,
  title={Eye tracking insights into physician behaviour with safe and unsafe explainable AI recommendations},
  author={Nagendran, Myura and Festor, Paul and Komorowski, Matthieu and Gordon, Anthony C and Faisal, Aldo A},
  journal={NPJ Digital Medicine},
  volume={7},
  number={1},
  pages={202},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{all-you-need,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{Lee2020Oblique,
title={Oblique Decision Trees from Derivatives of ReLU Networks},
author={Guang-He Lee and Tommi S. Jaakkola},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Bke8UR4FPB}
}

%%%%%% INTERPRETABILITY
@Article{rigourous,
      title={Towards A Rigorous Science of Interpretable Machine Learning}, 
      author={Finale Doshi-Velez and Been Kim},
      year={2017},
      eprint={1702.08608},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1702.08608}, 
}


@Article{lipton,
author = {Lipton, Zachary C.},
title = {The Mythos of Model Interpretability: In machine learning, the concept of interpretability is both important and slippery.},
year = {2018},
issue_date = {May-June 2018},
publisher = {Association for Computing Machinery},
volume = {16},
number = {3},
journal = {Queue},
pages = {31–57},
}

@Article{pmlr-v247-bressan24a,
  title = 	 {A Theory of Interpretable Approximations},
  author =       {Bressan, Marco and Cesa-Bianchi, Nicol{\`o} and Esposito, Emmanuel and Mansour, Yishay and Moran, Shay and Thiessen, Maximilian},
  journal = 	 {Proceedings of Thirty Seventh Conference on Learning Theory},
  pages = 	 {648--668},
  year = 	 {2024},
  volume = 	 {247},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
}

@Article{saux:hal-04192198,
  TITLE = {{Development and validation of an interpretable machine learning-based calculator for predicting 5-year weight trajectories after bariatric surgery: a multinational retrospective cohort SOPHIA study}},
  AUTHOR = {Saux, Patrick and Bauvin, Pierre and Raverdy, Violeta and Teigny, Julien and Verkindt, H{\'e}l{\`e}ne and Soumphonphakdy, Tomy and Debert, Maxence and Jacobs, Anne and Jacobs, Daan and Monpellier, Valerie and Lee, Phong Ching and Lim, Chin Hong and Andersson-Assarsson, Johanna C and Carlsson, Lena and Svensson, Per-Arne and Galtier, Florence and Dezfoulian, Guelareh and Moldovanu, Mihaela and Andrieux, Severine and Couster, Julien and Lepage, Marie and Lembo, Erminia and Verrastro, Ornella and Robert, Maud and Salminen, Paulina and Mingrone, Geltrude and Peterli, Ralph and Cohen, Ricardo V and Zerrweck, Carlos and Nocca, David and Le Roux, Carel W and Caiazzo, Robert and Preux, Philippe and Pattou, Fran{\c c}ois},
  URL = {https://hal.science/hal-04192198},
  JOURNAL = {{The Lancet Digital Health}},
  PUBLISHER = {{Elsevier}},
  YEAR = {2023},
  MONTH = Aug,
  DOI = {10.1016/S2589-7500(23)00135-8},
  KEYWORDS = {Bariatric Surgery ; Obesity ; Regression trees},
  PDF = {https://hal.science/hal-04192198v1/file/22tldig1227.pdf},
  HAL_ID = {hal-04192198},
  HAL_VERSION = {v1},
}

@Article{program-synth,
  title={Program synthesis},
  author={Gulwani, Sumit and Polozov, Oleksandr and Singh, Rishabh and others},
  journal={Foundations and Trends{\textregistered} in Programming Languages},
  volume={4},
  number={1-2},
  pages={1--119},
  year={2017},
  publisher={Now Publishers, Inc.}
}

@Article{lime,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135–1144},
numpages = {10},
keywords = {interpretable machine learning, interpretability, explaining machine learning, black box classifier},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@Article{study-0,
author = {Freitas, Alex A.},
title = {Comprehensible classification models: a position paper},
year = {2014},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/2594473.2594475},
doi = {10.1145/2594473.2594475},
abstract = {The vast majority of the literature evaluates the performance of classification models using only the criterion of predictive accuracy. This paper reviews the case for considering also the comprehensibility (interpretability) of classification models, and discusses the interpretability of five types of classification models, namely decision trees, classification rules, decision tables, nearest neighbors and Bayesian network classifiers. We discuss both interpretability issues which are specific to each of those model types and more generic interpretability issues, namely the drawbacks of using model size as the only criterion to evaluate the comprehensibility of a model, and the use of monotonicity constraints to improve the comprehensibility and acceptance of classification models by users.},
journal = {SIGKDD Explor. Newsl.},
month = mar,
pages = {1–10},
numpages = {10},
keywords = {Bayesian network classifiers, decision table, decision tree, monotonicity constraint, nearest neighbors, rule induction}
}

@Article{study-4,
title = {Selected techniques for data mining in medicine},
journal = {Artificial Intelligence in Medicine},
volume = {16},
number = {1},
pages = {3-23},
year = {1999},
note = {Data Mining Techniques and Applications in Medicine},
issn = {0933-3657},
doi = {https://doi.org/10.1016/S0933-3657(98)00062-1},
url = {https://www.sciencedirect.com/science/article/pii/S0933365798000621},
author = {Nada Lavrač},
keywords = {Data mining, Machine learning, Medical applications},
abstract = {Widespread use of medical information systems and explosive growth of medical databases require traditional manual data analysis to be coupled with methods for efficient computer-assisted analysis. This paper presents selected data mining techniques that can be applied in medicine, and in particular some machine learning techniques including the mechanisms that make them better suited for the analysis of medical databases (derivation of symbolic rules, use of background knowledge, sensitivity and specificity of induced descriptions). The importance of the interpretability of results of data analysis is discussed and illustrated on selected medical applications.}
}

@Article{study-2,
title = {Performance of classification models from a user perspective},
journal = {Decision Support Systems},
volume = {51},
number = {4},
pages = {782-793},
year = {2011},
note = {Recent Advances in Data, Text, and Media Mining \& Information Issues in Supply Chain and in Service System Design},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2011.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S016792361100042X},
author = {David Martens and Jan Vanthienen and Wouter Verbeke and Bart Baesens},
keywords = {Data mining, Classification, Metrics, Justifiability, Comprehensibility},
abstract = {This paper proposes a complete framework to assess the overall performance of classification models from a user perspective in terms of accuracy, comprehensibility, and justifiability. A review is provided of accuracy and comprehensibility measures, and a novel metric is introduced that allows one to measure the justifiability of classification models. Furthermore, taxonomy of domain constraints is introduced, and an overview of the existing approaches to impose constraints and include domain knowledge in data mining techniques is presented. Finally, justifiability metric is applied to a credit scoring and customer churn prediction case.}
}

@Article{study-3,
title = {Building comprehensible customer churn prediction models with advanced rule induction techniques},
journal = {Expert Systems with Applications},
volume = {38},
number = {3},
pages = {2354-2364},
year = {2011},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2010.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S0957417410008067},
author = {Wouter Verbeke and David Martens and Christophe Mues and Bart Baesens},
keywords = {Churn prediction, Data mining, Classification, Comprehensible rule induction, Ant Colony Optimization, ALBA},
abstract = {Customer churn prediction models aim to detect customers with a high propensity to attrite. Predictive accuracy, comprehensibility, and justifiability are three key aspects of a churn prediction model. An accurate model permits to correctly target future churners in a retention marketing campaign, while a comprehensible and intuitive rule-set allows to identify the main drivers for customers to churn, and to develop an effective retention strategy in accordance with domain knowledge. This paper provides an extended overview of the literature on the use of data mining in customer churn prediction modeling. It is shown that only limited attention has been paid to the comprehensibility and the intuitiveness of churn prediction models. Therefore, two novel data mining techniques are applied to churn prediction modeling, and benchmarked to traditional rule induction techniques such as C4.5 and RIPPER. Both AntMiner+ and ALBA are shown to induce accurate as well as comprehensible classification rule-sets. AntMiner+ is a high performing data mining technique based on the principles of Ant Colony Optimization that allows to include domain knowledge by imposing monotonicity constraints on the final rule-set. ALBA on the other hand combines the high predictive accuracy of a non-linear support vector machine model with the comprehensibility of the rule-set format. The results of the benchmarking experiments show that ALBA improves learning of classification techniques, resulting in comprehensible models with increased performance. AntMiner+ results in accurate, comprehensible, but most importantly justifiable models, unlike the other modeling techniques included in this study.}
}

@Article{study-1,
author = {Freitas, Alex A. and Wieser, Daniela C. and Apweiler, Rolf},
title = {On the Importance of Comprehensible Classification Models for Protein Function Prediction},
year = {2010},
issue_date = {January 2010},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {7},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2008.47},
doi = {10.1109/TCBB.2008.47},
abstract = {The literature on protein function prediction is currently dominated by works aimed at maximizing predictive accuracy, ignoring the important issues of validation and interpretation of discovered knowledge, which can lead to new insights and hypotheses that are biologically meaningful and advance the understanding of protein functions by biologists. The overall goal of this paper is to critically evaluate this approach, offering a refreshing new perspective on this issue, focusing not only on predictive accuracy but also on the comprehensibility of the induced protein function prediction models. More specifically, this paper aims to offer two main contributions to the area of protein function prediction. First, it presents the case for discovering comprehensible protein function prediction models from data, discussing in detail the advantages of such models, namely, increasing the confidence of the biologist in the system's predictions, leading to new insights about the data and the formulation of new biological hypotheses, and detecting errors in the data. Second, it presents a critical review of the pros and cons of several different knowledge representations that can be used in order to support the discovery of comprehensible protein function prediction models.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jan,
pages = {172–182},
numpages = {11},
keywords = {Biology, classifier design and evaluation, induction, machine learning.}
}


@misc{saliency,
      title={Visualizing and Understanding Atari Agents}, 
      author={Sam Greydanus and Anurag Koul and Jonathan Dodge and Alan Fern},
      year={2018},
      journal={arXiv},
}

@article{parbhoo,
title={Regional Tree Regularization for Interpretability in Deep Neural Networks}, 
volume={34}, 
url={https://ojs.aaai.org/index.php/AAAI/article/view/6112}, 
DOI={10.1609/aaai.v34i04.6112}, 
year={2020}, 
month={Apr.}, 
pages={6413-6421} }

@misc{maraboupy,
      title={Marabou 2.0: A Versatile Formal Analyzer of Neural Networks}, 
      author={Haoze Wu and Omri Isac and Aleksandar Zeljić and Teruhiro Tagomori and Matthew Daggitt and Wen Kokke and Idan Refaeli and Guy Amir and Kyle Julian and Shahaf Bassan and Pei Huang and Ori Lahav and Min Wu and Min Zhang and Ekaterina Komendantskaya and Guy Katz and Clark Barrett},
      year={2024},
      eprint={2401.14461},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2401.14461}, 
}

@Article{saliency2,
  title={Visualization of deep reinforcement learning using grad-CAM: how AI plays atari games?},
  author={Joo, Ho-Taek and Kim, Kyung-Joong},
  booktitle={2019 IEEE Conference on Games (CoG)},
  year={2019},
}

@misc{saliency3,
      title={Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning}, 
      author={Akanksha Atrey and Kaleigh Clary and David Jensen},
      year={2020},
      journal={arXiv},
}


@Article{lens-complexity,
  title={Model interpretability through the lens of computational complexity},
  author={Barcel{\'o}, Pablo and Monet, Mika{\"e}l and P{\'e}rez, Jorge and Subercaseaux, Bernardo},
  journal={Advances in neural information processing systems},
  year={2020}
}



@Article{empirical-evidence,
 author = {Mania, Horia and Guy, Aurelia and Recht, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Simple random search of static linear policies is competitive for reinforcement learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/7634ea65a4e6d9041cfd3f7de18e334a-Paper.pdf},
 volume = {31},
 year = {2018}
}

@misc{theory1,
      title={There is no Accuracy-Interpretability Tradeoff in Reinforcement Learning for Mazes}, 
      author={Yishay Mansour and Michal Moshkovitz and Cynthia Rudin},
      year={2022},
      eprint={2206.04266},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.04266}, 
}


@InProceedings{theory2,
  title = 	 {A Theory of Interpretable Approximations},
  author =       {Bressan, Marco and Cesa-Bianchi, Nicol{\`o} and Esposito, Emmanuel and Mansour, Yishay and Moran, Shay and Thiessen, Maximilian},
  booktitle = 	 {Proceedings of Thirty Seventh Conference on Learning Theory},
  pages = 	 {648--668},
  year = 	 {2024},
  editor = 	 {Agrawal, Shipra and Roth, Aaron},
  volume = 	 {247},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {30 Jun--03 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v247/bressan24a/bressan24a.pdf},
  url = 	 {https://proceedings.mlr.press/v247/bressan24a.html},
  abstract = 	 {Can a deep neural network be approximated by a small decision tree based on simple features? This question and its variants are behind the growing demand for machine learning models that are \emph{interpretable} by humans. In this work we study such questions by introducing \emph{interpretable approximations}, a notion that captures the idea of approximating a target concept $c$ by a small aggregation of concepts from some base class $\mathcal{H}$. In particular, we consider the approximation of a binary concept $c$ by decision trees based on a simple class $\mathcal{H}$ (e.g., of bounded VC dimension), and use the tree depth as a measure of complexity. Our primary contribution is the following remarkable trichotomy. For any given pair of $\mathcal{H}$ and $c$, exactly one of these cases holds: (i) $c$ cannot be approximated by $\mathcal{H}$ with arbitrary accuracy; (ii) $c$ can be approximated by $\mathcal{H}$ with arbitrary accuracy, but there exists no universal rate that bounds the complexity of the approximations as a function of the accuracy; or (iii) there exists a constant $\kappa$ that depends only on $\mathcal{H}$ and $c$ such that, for \emph{any} data distribution and \emph{any} desired accuracy level, $c$ can be approximated by $\mathcal{H}$ with a complexity not exceeding $\kappa$. This taxonomy stands in stark contrast to the landscape of supervised classification, which offers a complex array of distribution-free and universally learnable scenarios. We show that, in the case of interpretable approximations, even a slightly nontrivial a-priori guarantee on the complexity of approximations implies approximations with constant (distribution-free and accuracy-free) complexity. We extend our trichotomy to classes $\mathcal{H}$ of unbounded VC dimension and give characterizations of interpretability based on the algebra generated by $\mathcal{H}$.}
}



@Article{query,
author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
title = {A Survey of Methods for Explaining Black Box Models},
year = {2018},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3236009},
doi = {10.1145/3236009},
abstract = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {93},
numpages = {42},
keywords = {Open the black box, explanations, interpretability, transparent models}
}


%%%% OTHER

@Article{relunet,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}
@Article{mlp,
title = {Connectionist learning procedures},
journal = {Artificial Intelligence},
volume = {40},
number = {1},
pages = {185-234},
year = {1989},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(89)90049-0},
url = {https://www.sciencedirect.com/science/article/pii/0004370289900490},
author = {Geoffrey E. Hinton},
abstract = {A major goal of research on networks of neuron-like processing units is to discover efficient learning procedures that allow these networks to construct complex internal representations of their environment. The learning procedures must be capable of modifying the connection strengths in such a way that internal units which are not part of the input or output come to represent important features of the task domain. Several interesting gradient-descent procedures have recently been discovered. Each connection computes the derivative, with respect to the connection strength, of a global measure of the error in the performance of the network. The strength is then adjusted in the direction that decreases the error. These relatively simple, gradient-descent learning procedures work well for small tasks and the new challenge is to find ways of improving their convergence rate and their generalization abilities so that they can be applied to larger, more realistic tasks.}
}

@Article{z3,
author = {De Moura, Leonardo and Bj\o{}rner, Nikolaj},
title = {Z3: an efficient SMT solver},
year = {2008},
isbn = {3540787992},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Satisfiability Modulo Theories (SMT) problem is a decision problem for logical first order formulas with respect to combinations of background theories such as: arithmetic, bit-vectors, arrays, and uninterpreted functions. Z3 is a new and efficient SMT Solver freely available from Microsoft Research. It is used in various software verification and analysis applications.},
booktitle = {Proceedings of the Theory and Practice of Software, 14th International Conference on Tools and algorithms for the Construction and Analysis of Systems},
pages = {337–340},
numpages = {4},
location = {Budapest, Hungary},
series = {TACAS'08/ETAPS'08}
}

@Article{adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      juornal={3rd International Conference on Learning Representations, ICLR 2015},
      year={2015}
}